{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_en-zh_translate",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcqY8byREj577XIpcyZxWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoguowei/test/blob/main/Transformer_en_zh_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17ig8SmQMzCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8fbd131-8a58-4a37-d89e-619f109b3241"
      },
      "source": [
        "!pip install tensorflow_datasets\n",
        "!git clone https://github.com/xiaoguowei/test.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.3.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (3.17.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (5.2.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (4.62.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow_datasets) (3.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.53.0)\n",
            "Cloning into 'test'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 23 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktzqehAWNDhj"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OALRNFcINjK1"
      },
      "source": [
        "# **路徑**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LD7p0YKNQlO"
      },
      "source": [
        "output_dir = \"test/nmt\"\n",
        "en_vocab_file = os.path.join(output_dir, \"en_vocab\") #已有英文字典的路径 test/nmt/en_vocab\n",
        "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\") ##已有中文字典的路径 test/nmt/zh_vocab\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(output_dir, 'logs')\n",
        "download_dir = \"tensorflow-datasets/downloads\" #下载数据\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYeluzZ7Nu0R"
      },
      "source": [
        "#**加載數據**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZnRViXRybRv"
      },
      "source": [
        "wmt19_translate/zh-en\n",
        "\n",
        "\n",
        "*   newscommentary_v14(311556筆)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hNKdM_MNanu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eb7b68-9abc-477d-983a-750c65f3b4e1"
      },
      "source": [
        "list_tfds = tfds.list_builders()\n",
        "tfds_zh_en=tfds.builder(\"wmt19_translate/zh-en\")\n",
        "config = tfds.translate.wmt.WmtConfig(\n",
        "  version=tfds.core.Version('0.0.3', experiments=None),\n",
        "  language_pair=(\"zh\", \"en\"),\n",
        "  subsets={\n",
        "    tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
        "  }\n",
        ")\n",
        "\n",
        "builder = tfds.builder(\"wmt_translate\", config=config)\n",
        "builder.download_and_prepare(download_dir=download_dir)\n",
        "clear_output()\n",
        "\n",
        "train_examples = builder.as_dataset(split=tfds.Split.TRAIN, as_supervised=True)\n",
        "print(\"數據集總共有：\",len(train_examples))\n",
        "# for en,zh in train_examples.take(1): #[en,zh]\n",
        "#     print(\"Datasets_en原始數據: \", en)\n",
        "#     print(\"Datasets_zh原始數據: \", zh)\n",
        "#     print(\"解碼後的en: \",en.numpy().decode(\"utf-8\"))\n",
        "#     print(\"解碼後的zh: \",zh.numpy().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "數據集總共有： 311556\n",
            "Datasets_en原始數據:  tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
            "Datasets_zh原始數據:  tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "解碼後的en:  The fear is real and visceral, and politicians ignore it at their peril.\n",
            "解碼後的zh:  这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pODFbELkOL0R"
      },
      "source": [
        "**#中英字典**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3HO51IkN6gy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a129c67-b689-45f8-96fb-c02e0491a594"
      },
      "source": [
        "try:\n",
        "  tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
        "  print(f\"載入已建立的英文字典： {en_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的英文字典，從頭建立。\")\n",
        "  tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples), \n",
        "      target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_en.save_to_file(en_vocab_file)\n",
        "print(f\"字典大小：{tokenizer_en.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{tokenizer_en.subwords[:10]}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "  tokenizer_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
        "  print(f\"載入已建立的中文字典： {zh_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的中文字典，從頭建立。\")\n",
        "  tokenizer_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples), \n",
        "      target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_zh.save_to_file(zh_vocab_file)\n",
        "print(f\"字典大小：{tokenizer_zh.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{tokenizer_zh.subwords[:10]}\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "載入已建立的英文字典： test/nmt/en_vocab\n",
            "字典大小：8177\n",
            "前 10 個 subwords：[', ', 'the_', 'to_', 'of_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
            "\n",
            "載入已建立的中文字典： test/nmt/zh_vocab\n",
            "字典大小：8212\n",
            "前 10 個 subwords：['，', '。', '的', '和', '、', ' — — ', '在', '（', '了', '是']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77j8cZ5gOQgI"
      },
      "source": [
        "#因為 tf.data.Dataset 裡頭都是在操作 Tensors（而非 Python 字串），\n",
        "#所以這個 encode 函式預期的輸入也是 TensorFlow 裡的 Eager Tensors。\n",
        "#但只要我們使用 numpy() 將 Tensor 裡的實際字串取出以後，做的事情就跟上一節完全相同\n",
        "\n",
        "#用字典將原文轉換成相對應的索引序列，並且序列添加開頭(BOS)和結束(EOS)Token\n",
        "def encode(en_token,zh_token):\n",
        "  # 因為字典的索引從 0 開始，\n",
        "  # 我們可以使用 tokenizer_en.vocab_size 這個值作為 BOS 的索引值\n",
        "  # 用 tokenizer_en.vocab_size + 1 作為 EOS 的索引值\n",
        "  en_indices = [tokenizer_en.vocab_size] + tokenizer_en.encode(en_token.numpy()) + [tokenizer_en.vocab_size + 1]\n",
        "  # 同理，不過是使用中文字典的最後一個索引 + 1\n",
        "  zh_indices = [tokenizer_zh.vocab_size] + tokenizer_zh.encode(zh_token.numpy()) + [tokenizer_zh.vocab_size + 1]\n",
        "  \n",
        "  return en_indices, zh_indices\n",
        "\n",
        "# 使用 tf.py_function 將我們剛剛定義的 encode 函式包成一個以 eager 模式執行的 TensorFlow Op\n",
        "def tf_encode(en_t, zh_t):\n",
        "  # 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors\n",
        "  # 要到 `tf.py_funtion` 裡頭才是\n",
        "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
        "  return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "#去掉長度超過40的數據,剩餘217967筆\n",
        "MAX_LENGTH = 40\n",
        "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
        "  # en, zh 分別代表英文與中文的索引序列\n",
        "  return tf.logical_and(tf.size(en) <= max_length,tf.size(zh) <= max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVnrye8yOz6q"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "# 訓練集\n",
        "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
        "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
        "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
        "                 .cache() # 加快讀取數據\n",
        "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
        "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
        "                               padded_shapes=([-1], [-1]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "\n",
        "# en_batch, zh_batch = next(iter(train_dataset))\n",
        "# print(\"英文索引序列的 batch\")\n",
        "# print(en_batch)\n",
        "# print('-' * 20)\n",
        "# print(\"中文索引序列的 batch\")\n",
        "# print(zh_batch)\n",
        "                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqeUGelQe_KT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgstCAce-Pn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfnJq08XPgL9"
      },
      "source": [
        "#Transformer\n",
        "\n",
        "*   Positional Encoding\n",
        "*   \n",
        "\n",
        "\n",
        "*   清單項目\n",
        "*   清單項目\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOEpbGNFPWDi"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # 将 sin 应用于数组中的偶数索引（indices）；2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # 将 cos 应用于数组中的奇数索引；2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "#用來識別序列實際的內容到哪裡。此遮罩負責的就是將序列中被補 0 的地方（也就是 <pad>）的位置蓋住，讓 Transformer 可以避免「關注」到這些位置\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # 添加额外的维度来将填充加到\n",
        "  # 注意力对数（logits）。\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "#用來確保 Decoder 在進行自注意力機制時輸出序列裡頭的每個子詞只會關注到自己之前（左邊）的字詞，\n",
        "#不會不小心關注到未來（右邊）理論上還沒被 Decoder 生成的子詞\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"计算注意力权重。\n",
        "  q, k, v 必须具有匹配的前置维度。\n",
        "  k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
        "  虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
        "  但是 mask 必须能进行广播转换以便求和。\n",
        "\n",
        "  参数:\n",
        "    q: 请求的形状 == (..., seq_len_q, depth)\n",
        "    k: 主键的形状 == (..., seq_len_k, depth)\n",
        "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
        "    mask: Float 张量，其形状能转换成\n",
        "          (..., seq_len_q, seq_len_k)。默认为None。\n",
        "\n",
        "  返回值:\n",
        "    输出，注意力权重\n",
        "  \"\"\"\n",
        "  ## 將 `q`、 `k` 做點積再 scale\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # 缩放 matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # 将 mask 加入到缩放的张量上。\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n",
        "  # 相加等于1。\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"分拆最后一个维度到 (num_heads, depth).\n",
        "    转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # 将嵌入和位置编码相加。\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz50SsnqRFQh"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W35UXPjNRPWI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DetZrYx7Ppr0"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "  # 编码器填充遮挡\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # 在解码器的第二个注意力模块使用。\n",
        "  # 该填充遮挡用于遮挡编码器的输出。\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # 在解码器的第一个注意力模块使用。\n",
        "  # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsF1Ss8gSqQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8a9ab6-5a30-4b76-be90-4bc6f9372a85"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_en.vocab_size + 2\n",
        "target_vocab_size = tokenizer_zh.vocab_size + 2\n",
        "print(\"input_vocab_size: \",input_vocab_size )\n",
        "print(\"target_vocab_size: \",target_vocab_size )\n",
        "dropout_rate = 0.1\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_vocab_size:  8179\n",
            "target_vocab_size:  8214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T67TgjeSFBK",
        "outputId": "104f6722-e7b4-4523-8d46-6670dae256dc"
      },
      "source": [
        "\n",
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# 如果检查点存在，则恢复最新的检查点。\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')\n",
        "\n",
        "EPOCHS = 2\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "\n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  if (epoch + 3) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7686 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 4.9210 Accuracy 0.0011\n",
            "Epoch 1 Batch 100 Loss 4.8429 Accuracy 0.0131\n",
            "Epoch 1 Batch 150 Loss 4.7996 Accuracy 0.0177\n",
            "Epoch 1 Batch 200 Loss 4.7596 Accuracy 0.0202\n",
            "Epoch 1 Batch 250 Loss 4.7069 Accuracy 0.0235\n",
            "Epoch 1 Batch 300 Loss 4.6469 Accuracy 0.0277\n",
            "Epoch 1 Batch 350 Loss 4.5884 Accuracy 0.0316\n",
            "Epoch 1 Batch 400 Loss 4.5289 Accuracy 0.0353\n",
            "Epoch 1 Batch 450 Loss 4.4821 Accuracy 0.0388\n",
            "Epoch 1 Batch 500 Loss 4.4407 Accuracy 0.0420\n",
            "Epoch 1 Batch 550 Loss 4.3941 Accuracy 0.0445\n",
            "Epoch 1 Batch 600 Loss 4.3641 Accuracy 0.0466\n",
            "Epoch 1 Batch 650 Loss 4.3322 Accuracy 0.0485\n",
            "Epoch 1 Batch 700 Loss 4.3064 Accuracy 0.0502\n",
            "Epoch 1 Batch 750 Loss 4.2809 Accuracy 0.0517\n",
            "Epoch 1 Batch 800 Loss 4.2613 Accuracy 0.0529\n",
            "Epoch 1 Batch 850 Loss 4.2409 Accuracy 0.0542\n",
            "Epoch 1 Batch 900 Loss 4.2174 Accuracy 0.0551\n",
            "Epoch 1 Batch 950 Loss 4.1945 Accuracy 0.0561\n",
            "Epoch 1 Batch 1000 Loss 4.1770 Accuracy 0.0570\n",
            "Epoch 1 Batch 1050 Loss 4.1603 Accuracy 0.0578\n",
            "Epoch 1 Batch 1100 Loss 4.1399 Accuracy 0.0585\n",
            "Epoch 1 Batch 1150 Loss 4.1246 Accuracy 0.0592\n",
            "Epoch 1 Batch 1200 Loss 4.1061 Accuracy 0.0598\n",
            "Epoch 1 Batch 1250 Loss 4.0894 Accuracy 0.0604\n",
            "Epoch 1 Batch 1300 Loss 4.0759 Accuracy 0.0610\n",
            "Epoch 1 Batch 1350 Loss 4.0597 Accuracy 0.0615\n",
            "Epoch 1 Batch 1400 Loss 4.0441 Accuracy 0.0619\n",
            "Epoch 1 Batch 1450 Loss 4.0307 Accuracy 0.0625\n",
            "Epoch 1 Batch 1500 Loss 4.0182 Accuracy 0.0630\n",
            "Epoch 1 Batch 1550 Loss 4.0058 Accuracy 0.0634\n",
            "Epoch 1 Batch 1600 Loss 3.9907 Accuracy 0.0638\n",
            "Epoch 1 Batch 1650 Loss 3.9781 Accuracy 0.0642\n",
            "Epoch 1 Batch 1700 Loss 3.9665 Accuracy 0.0647\n",
            "Epoch 1 Batch 1750 Loss 3.9536 Accuracy 0.0651\n",
            "Epoch 1 Batch 1800 Loss 3.9396 Accuracy 0.0655\n",
            "Epoch 1 Batch 1850 Loss 3.9272 Accuracy 0.0658\n",
            "Epoch 1 Batch 1900 Loss 3.9147 Accuracy 0.0662\n",
            "Epoch 1 Batch 1950 Loss 3.9043 Accuracy 0.0666\n",
            "Epoch 1 Batch 2000 Loss 3.8919 Accuracy 0.0669\n",
            "Epoch 1 Batch 2050 Loss 3.8806 Accuracy 0.0673\n",
            "Epoch 1 Batch 2100 Loss 3.8697 Accuracy 0.0676\n",
            "Epoch 1 Batch 2150 Loss 3.8574 Accuracy 0.0679\n",
            "Epoch 1 Batch 2200 Loss 3.8458 Accuracy 0.0682\n",
            "Epoch 1 Batch 2250 Loss 3.8351 Accuracy 0.0685\n",
            "Epoch 1 Batch 2300 Loss 3.8246 Accuracy 0.0689\n",
            "Epoch 1 Batch 2350 Loss 3.8148 Accuracy 0.0692\n",
            "Epoch 1 Batch 2400 Loss 3.8037 Accuracy 0.0695\n",
            "Epoch 1 Batch 2450 Loss 3.7941 Accuracy 0.0699\n",
            "Epoch 1 Batch 2500 Loss 3.7829 Accuracy 0.0701\n",
            "Epoch 1 Batch 2550 Loss 3.7728 Accuracy 0.0705\n",
            "Epoch 1 Batch 2600 Loss 3.7629 Accuracy 0.0708\n",
            "Epoch 1 Batch 2650 Loss 3.7529 Accuracy 0.0711\n",
            "Epoch 1 Batch 2700 Loss 3.7428 Accuracy 0.0714\n",
            "Epoch 1 Batch 2750 Loss 3.7326 Accuracy 0.0718\n",
            "Epoch 1 Batch 2800 Loss 3.7231 Accuracy 0.0721\n",
            "Epoch 1 Batch 2850 Loss 3.7139 Accuracy 0.0724\n",
            "Epoch 1 Batch 2900 Loss 3.7050 Accuracy 0.0727\n",
            "Epoch 1 Batch 2950 Loss 3.6958 Accuracy 0.0731\n",
            "Epoch 1 Batch 3000 Loss 3.6868 Accuracy 0.0734\n",
            "Epoch 1 Batch 3050 Loss 3.6784 Accuracy 0.0737\n",
            "Epoch 1 Batch 3100 Loss 3.6693 Accuracy 0.0741\n",
            "Epoch 1 Batch 3150 Loss 3.6599 Accuracy 0.0744\n",
            "Epoch 1 Batch 3200 Loss 3.6513 Accuracy 0.0748\n",
            "Epoch 1 Batch 3250 Loss 3.6419 Accuracy 0.0751\n",
            "Epoch 1 Batch 3300 Loss 3.6332 Accuracy 0.0755\n",
            "Epoch 1 Batch 3350 Loss 3.6245 Accuracy 0.0758\n",
            "Epoch 1 Batch 3400 Loss 3.6153 Accuracy 0.0762\n",
            "Epoch 1 Loss 3.6144 Accuracy 0.0762\n",
            "Time taken for 1 epoch: 911.2819776535034 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 3.1364 Accuracy 0.0872\n",
            "Epoch 2 Batch 50 Loss 3.0047 Accuracy 0.1020\n",
            "Epoch 2 Batch 100 Loss 3.0109 Accuracy 0.1018\n",
            "Epoch 2 Batch 150 Loss 3.0247 Accuracy 0.1026\n",
            "Epoch 2 Batch 200 Loss 3.0138 Accuracy 0.1030\n",
            "Epoch 2 Batch 250 Loss 3.0024 Accuracy 0.1032\n",
            "Epoch 2 Batch 300 Loss 2.9950 Accuracy 0.1036\n",
            "Epoch 2 Batch 350 Loss 2.9955 Accuracy 0.1042\n",
            "Epoch 2 Batch 400 Loss 2.9858 Accuracy 0.1046\n",
            "Epoch 2 Batch 450 Loss 2.9773 Accuracy 0.1050\n",
            "Epoch 2 Batch 500 Loss 2.9691 Accuracy 0.1052\n",
            "Epoch 2 Batch 550 Loss 2.9624 Accuracy 0.1059\n",
            "Epoch 2 Batch 600 Loss 2.9521 Accuracy 0.1061\n",
            "Epoch 2 Batch 650 Loss 2.9458 Accuracy 0.1066\n",
            "Epoch 2 Batch 700 Loss 2.9411 Accuracy 0.1071\n",
            "Epoch 2 Batch 750 Loss 2.9331 Accuracy 0.1075\n",
            "Epoch 2 Batch 800 Loss 2.9291 Accuracy 0.1080\n",
            "Epoch 2 Batch 850 Loss 2.9281 Accuracy 0.1086\n",
            "Epoch 2 Batch 900 Loss 2.9232 Accuracy 0.1091\n",
            "Epoch 2 Batch 950 Loss 2.9161 Accuracy 0.1096\n",
            "Epoch 2 Batch 1000 Loss 2.9108 Accuracy 0.1102\n",
            "Epoch 2 Batch 1050 Loss 2.9057 Accuracy 0.1107\n",
            "Epoch 2 Batch 1100 Loss 2.8986 Accuracy 0.1112\n",
            "Epoch 2 Batch 1150 Loss 2.8912 Accuracy 0.1117\n",
            "Epoch 2 Batch 1200 Loss 2.8860 Accuracy 0.1122\n",
            "Epoch 2 Batch 1250 Loss 2.8787 Accuracy 0.1128\n",
            "Epoch 2 Batch 1300 Loss 2.8744 Accuracy 0.1134\n",
            "Epoch 2 Batch 1350 Loss 2.8674 Accuracy 0.1140\n",
            "Epoch 2 Batch 1400 Loss 2.8622 Accuracy 0.1145\n",
            "Epoch 2 Batch 1450 Loss 2.8561 Accuracy 0.1150\n",
            "Epoch 2 Batch 1500 Loss 2.8495 Accuracy 0.1156\n",
            "Epoch 2 Batch 1550 Loss 2.8440 Accuracy 0.1161\n",
            "Epoch 2 Batch 1600 Loss 2.8387 Accuracy 0.1167\n",
            "Epoch 2 Batch 1650 Loss 2.8329 Accuracy 0.1172\n",
            "Epoch 2 Batch 1700 Loss 2.8278 Accuracy 0.1178\n",
            "Epoch 2 Batch 1750 Loss 2.8210 Accuracy 0.1182\n",
            "Epoch 2 Batch 1800 Loss 2.8149 Accuracy 0.1188\n",
            "Epoch 2 Batch 1850 Loss 2.8075 Accuracy 0.1193\n",
            "Epoch 2 Batch 1900 Loss 2.8012 Accuracy 0.1199\n",
            "Epoch 2 Batch 1950 Loss 2.7951 Accuracy 0.1205\n",
            "Epoch 2 Batch 2000 Loss 2.7891 Accuracy 0.1210\n",
            "Epoch 2 Batch 2050 Loss 2.7834 Accuracy 0.1215\n",
            "Epoch 2 Batch 2100 Loss 2.7778 Accuracy 0.1221\n",
            "Epoch 2 Batch 2150 Loss 2.7715 Accuracy 0.1227\n",
            "Epoch 2 Batch 2200 Loss 2.7657 Accuracy 0.1232\n",
            "Epoch 2 Batch 2250 Loss 2.7604 Accuracy 0.1238\n",
            "Epoch 2 Batch 2300 Loss 2.7540 Accuracy 0.1243\n",
            "Epoch 2 Batch 2350 Loss 2.7491 Accuracy 0.1248\n",
            "Epoch 2 Batch 2400 Loss 2.7437 Accuracy 0.1253\n",
            "Epoch 2 Batch 2450 Loss 2.7372 Accuracy 0.1258\n",
            "Epoch 2 Batch 2500 Loss 2.7311 Accuracy 0.1263\n",
            "Epoch 2 Batch 2550 Loss 2.7246 Accuracy 0.1269\n",
            "Epoch 2 Batch 2600 Loss 2.7178 Accuracy 0.1274\n",
            "Epoch 2 Batch 2650 Loss 2.7123 Accuracy 0.1279\n",
            "Epoch 2 Batch 2700 Loss 2.7069 Accuracy 0.1285\n",
            "Epoch 2 Batch 2750 Loss 2.7013 Accuracy 0.1289\n",
            "Epoch 2 Batch 2800 Loss 2.6959 Accuracy 0.1295\n",
            "Epoch 2 Batch 2850 Loss 2.6906 Accuracy 0.1300\n",
            "Epoch 2 Batch 2900 Loss 2.6853 Accuracy 0.1305\n",
            "Epoch 2 Batch 2950 Loss 2.6797 Accuracy 0.1310\n",
            "Epoch 2 Batch 3000 Loss 2.6747 Accuracy 0.1315\n",
            "Epoch 2 Batch 3050 Loss 2.6693 Accuracy 0.1320\n",
            "Epoch 2 Batch 3100 Loss 2.6644 Accuracy 0.1325\n",
            "Epoch 2 Batch 3150 Loss 2.6593 Accuracy 0.1330\n",
            "Epoch 2 Batch 3200 Loss 2.6540 Accuracy 0.1335\n",
            "Epoch 2 Batch 3250 Loss 2.6487 Accuracy 0.1339\n",
            "Epoch 2 Batch 3300 Loss 2.6436 Accuracy 0.1344\n",
            "Epoch 2 Batch 3350 Loss 2.6386 Accuracy 0.1349\n",
            "Epoch 2 Batch 3400 Loss 2.6337 Accuracy 0.1354\n",
            "Epoch 2 Loss 2.6332 Accuracy 0.1354\n",
            "Time taken for 1 epoch: 439.3651216030121 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFUpDTqtSPSz"
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_en.vocab_size]\n",
        "  end_token = [tokenizer_en.vocab_size + 1]\n",
        "\n",
        "  # 输入语句是英文，增加开始和结束标记\n",
        "  inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # 因为目标是中文，输入 transformer 的第一个词应该是\n",
        "  # 英语的开始标记。\n",
        "  decoder_input = [tokenizer_zh.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "    # 从 seq_len 维度选择最后一个词\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 如果 predicted_id 等于结束标记，就返回结果\n",
        "    if predicted_id == tokenizer_zh.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "#view attention\n",
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  sentence = tokenizer_zh.encode(sentence)\n",
        "\n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "\n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "    # 画出注意力权重\n",
        "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "\n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "\n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "\n",
        "    ax.set_xticklabels(\n",
        "        ['<start>']+[tokenizer_zh.decode([i]) for i in sentence]+['<end>'], \n",
        "        fontdict=fontdict, rotation=90)\n",
        "\n",
        "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                        if i < tokenizer_en.vocab_size], \n",
        "                       fontdict=fontdict)\n",
        "\n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUUnlTSYU5Yv"
      },
      "source": [
        "import matplotlib as mpl\n",
        "# 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文\n",
        "zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/SimHei/simhei.ttf')\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "def translate_zh_en(sentence,plot=''):\n",
        "  # 取得預測的中文索引序列\n",
        "  translate_result, attention_weights = evaluate(sentence)\n",
        "\n",
        "  # 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
        "  target_vocab_size = tokenizer_zh.vocab_size\n",
        "  predicted_seq_without_bos_eos = [idx for idx in translate_result \n",
        "                                   if idx < target_vocab_size]\n",
        "  predicted_sentence = tokenizer_zh.decode(predicted_seq_without_bos_eos)\n",
        "\n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, translate_result, plot)\n",
        "\n",
        "  print(\"Input sentence: \", sentence)\n",
        "  print(\"predicted_seq_index: \", predicted_seq_without_bos_eos)\n",
        "  print(\"predicted_sentence: \", predicted_sentence)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "xQH9TAEMqomS",
        "outputId": "6e9360b9-4b5b-434c-de3e-eb09cf26416b"
      },
      "source": [
        "translate_zh_en(sentence=\"China, India, and others have enjoyed continuing economic growth.\",plot='decoder_layer4_block2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 8 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence:  China, India, and others have enjoyed continuing economic growth.\n",
            "predicted_seq_index:  [<tf.Tensor: shape=(), dtype=int32, numpy=45>, <tf.Tensor: shape=(), dtype=int32, numpy=5>, <tf.Tensor: shape=(), dtype=int32, numpy=3970>, <tf.Tensor: shape=(), dtype=int32, numpy=1506>, <tf.Tensor: shape=(), dtype=int32, numpy=60>, <tf.Tensor: shape=(), dtype=int32, numpy=255>, <tf.Tensor: shape=(), dtype=int32, numpy=780>, <tf.Tensor: shape=(), dtype=int32, numpy=2>]\n",
            "predicted_sentence:  中国、印度和其他国家都拥有经济增长。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_2Cs1hEtdF5",
        "outputId": "e72f5d8e-ca31-4cd2-bca3-b8f98facab0b"
      },
      "source": [
        "transformer.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder (Encoder)            multiple                  1840000   \n",
            "_________________________________________________________________\n",
            "decoder (Decoder)            multiple                  2109696   \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             multiple                  1059606   \n",
            "=================================================================\n",
            "Total params: 5,009,302\n",
            "Trainable params: 5,009,302\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrVuOMp6tg_F"
      },
      "source": [
        "import matplotlib as mpl\n",
        "# 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文\n",
        "zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/SimHei/simhei.ttf')\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "# 這個函式將英 -> 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果\n",
        "def plot_attention_weights(attention_weights, sentence, predicted_seq, layer_name, max_len_tar=None):\n",
        "    \n",
        "  fig = plt.figure(figsize=(17, 7))\n",
        "  \n",
        "  sentence = tokenizer_en.encode(sentence)\n",
        "  \n",
        "  # 只顯示中文序列前 `max_len_tar` 個字以避免畫面太過壅擠\n",
        "  if max_len_tar:\n",
        "    predicted_seq = predicted_seq[:max_len_tar]\n",
        "  else:\n",
        "    max_len_tar = len(predicted_seq)\n",
        "  \n",
        "  # 將某一個特定 Decoder layer 裡頭的 MHA 1 或 MHA2 的注意權重拿出來並去掉 batch 維度\n",
        "  attention_weights = tf.squeeze(attention_weights[layer_name], axis=0)  \n",
        "  # (num_heads, tar_seq_len, inp_seq_len)\n",
        "  \n",
        "  # 將每個 head 的注意權重畫出\n",
        "  for head in range(attention_weights.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head + 1)\n",
        "\n",
        "    # [注意]我為了將長度不短的英文子詞顯示在 y 軸，將注意權重做了 transpose\n",
        "    attn_map = np.transpose(attention_weights[head][:max_len_tar, :])\n",
        "    ax.matshow(attn_map, cmap='viridis')  # (inp_seq_len, tar_seq_len)\n",
        "    \n",
        "    fontdict = {\"fontproperties\": zhfont}\n",
        "    \n",
        "    ax.set_xticks(range(max(max_len_tar, len(predicted_seq))))\n",
        "    ax.set_xlim(-0.5, max_len_tar -1.5)\n",
        "    \n",
        "    ax.set_yticks(range(len(sentence) + 2))\n",
        "    ax.set_xticklabels([tokenizer_zh.decode([i]) for i in predicted_seq \n",
        "                        if i < tokenizer_zh.vocab_size], \n",
        "                       fontdict=fontdict, fontsize=18)    \n",
        "    \n",
        "    ax.set_yticklabels(\n",
        "        ['<start>'] + [tokenizer_en.decode([i]) for i in sentence] + ['<end>'], \n",
        "        fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head + 1))\n",
        "    ax.tick_params(axis=\"x\", labelsize=12)\n",
        "    ax.tick_params(axis=\"y\", labelsize=12)\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NhTX_Z-4uCJx",
        "outputId": "5f17c615-75e4-4c7d-f921-34668ce899be"
      },
      "source": [
        "sentence = \"China, India, and others have enjoyed continuing economic growth.\"\n",
        "predicted_seq, attention_weights = evaluate(sentence)\n",
        "layer_name = f\"decoder_layer{num_layers}_block2\"\n",
        "plot_attention_weights(attention_weights, sentence, predicted_seq, layer_name, max_len_tar=18)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-87c73b13a4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"decoder_layer{num_layers}_block2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_tar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-e88a16b8ed12>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[0;34m(attention_weights, sentence, predicted_seq, layer_name, max_len_tar)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mtight_layout\u001b[0;34m(pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         labels) will fit into. Default is (0, 0, 1, 1).\n\u001b[1;32m   1336\u001b[0m     \"\"\"\n\u001b[0;32m-> 1337\u001b[0;31m     \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_pad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mtight_layout\u001b[0;34m(self, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             kwargs = get_tight_layout_figure(\n\u001b[1;32m   2495\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplotspec_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m                 pad=pad, h_pad=h_pad, w_pad=w_pad, rect=rect)\n\u001b[0m\u001b[1;32m   2497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/tight_layout.py\u001b[0m in \u001b[0;36mget_tight_layout_figure\u001b[0;34m(fig, axes_list, subplotspec_list, renderer, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m    358\u001b[0m                                      \u001b[0msubplot_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                                      \u001b[0max_bbox_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max_bbox_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                                      pad=pad, h_pad=h_pad, w_pad=w_pad)\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# kwargs can be none if tight_layout fails...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/tight_layout.py\u001b[0m in \u001b[0;36mauto_adjust_subplotpars\u001b[0;34m(fig, renderer, nrows_ncols, num1num2_list, subplot_list, ax_bbox_list, pad, h_pad, w_pad, rect)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         tight_bbox_raw = union([ax.get_tightbbox(renderer) for ax in subplots\n\u001b[0m\u001b[1;32m    110\u001b[0m                                 if ax.get_visible()])\n\u001b[1;32m    111\u001b[0m         tight_bbox = TransformedBbox(tight_bbox_raw,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/tight_layout.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         tight_bbox_raw = union([ax.get_tightbbox(renderer) for ax in subplots\n\u001b[0;32m--> 110\u001b[0;31m                                 if ax.get_visible()])\n\u001b[0m\u001b[1;32m    111\u001b[0m         tight_bbox = TransformedBbox(tight_bbox_raw,\n\u001b[1;32m    112\u001b[0m                                      fig.transFigure.inverted())\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4323\u001b[0;31m             \u001b[0mbb_xaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_xaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4325\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2006\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2007\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[0;34m(self, prop)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[1;32m    247\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[0;34m(filename, hinting_factor)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.hinting_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     return _get_font(os.fspath(filename), hinting_factor,\n\u001b[0;32m-> 1329\u001b[0;31m                      _kerning_factor=rcParams['text.kerning_factor'])\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/share/fonts/SimHei/simhei.ttf'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7fa27b6d05f0> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[0;34m(self, prop)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[1;32m    247\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[0;34m(filename, hinting_factor)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.hinting_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     return _get_font(os.fspath(filename), hinting_factor,\n\u001b[0;32m-> 1329\u001b[0;31m                      _kerning_factor=rcParams['text.kerning_factor'])\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/share/fonts/SimHei/simhei.ttf'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m-> 1176\u001b[0;31m                  for tick in ticks if tick.label2.get_visible()])\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[0;34m(self, prop)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[1;32m    247\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[0;34m(filename, hinting_factor)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.hinting_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m     return _get_font(os.fspath(filename), hinting_factor,\n\u001b[0;32m-> 1329\u001b[0;31m                      _kerning_factor=rcParams['text.kerning_factor'])\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/share/fonts/SimHei/simhei.ttf'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1224x504 with 8 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}